{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-datareader\n",
    "!pip install \"yfinance[nospam]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cd27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as web\n",
    "import time\n",
    "from lxml import html\n",
    "import os\n",
    "import yfinance as yf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d54273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sp500_tickers():\n",
    "    # Mengambil halaman dan membuat soup\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "    \n",
    "    # Mencari tabel yang berisi data ticker\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    \n",
    "    tickers = []\n",
    "    # Mengiterasi setiap baris tabel kecuali header\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        # Mendapatkan data dari tiga kolom yang diinginkan\n",
    "        ticker = row.find_all('td')[0].text.strip()\n",
    "        company_name = row.find_all('td')[1].text.strip()\n",
    "        sector = row.find_all('td')[3].text.strip()\n",
    "        \n",
    "        # Menyimpan data ke list sebagai tuple\n",
    "        tickers.append({'ticker' : ticker, 'company name' : company_name, 'sektor' : sector})\n",
    "\n",
    "    # Menyimpan data ticker ke file pickle\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "\n",
    "    # Mencetak daftar ticker untuk verifikasi\n",
    "    print(tickers)\n",
    "\n",
    "    return tickers\n",
    "\n",
    "# Memanggil fungsi untuk menjalankan dan menyimpan ticker\n",
    "save_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515b58f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Timeseries data in Yahoo\n",
    "def get_data_from_yahoo(reload_sp500 = False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs2'):\n",
    "        os.makedirs('stock_dfs2')\n",
    "    \n",
    "    start = dt.datetime(2000,1,1)\n",
    "    end = dt.datetime(2020,5,28)\n",
    "\n",
    "    # Grab all ticker data\n",
    "    for s in tickers[401:500]:\n",
    "        print(s)\n",
    "        stock = s['ticker']\n",
    "        if not os.path.exists('stock_dfs2/{}.csv'.format(stock)):\n",
    "            try:\n",
    "                kk = yf.Ticker(stock)\n",
    "                end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "                df = kk.history(start='2020-01-01',end=end_date,interval='1d')\n",
    "                df.to_csv('stock_dfs2/{}.csv'.format(stock))\n",
    "            except:\n",
    "                print(f\"Problems retrieving data for {stock}. Skipping!\")\n",
    "            else:\n",
    "                print('Already have {}'.format(stock))\n",
    "\n",
    "get_data_from_yahoo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de19fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_data_yahoo(stock_code,endpoint):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'DNT': '1', \n",
    "        'Connection': 'keep-alive'\n",
    "    }\n",
    "\n",
    "    url = 'https://finance.yahoo.com/quote/' + stock_code + '/' + endpoint + '/'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(response)\n",
    "    tree = html.fromstring(response.content)\n",
    "    divs = tree.xpath(\"//div[contains(@class, 'column') and contains(@class, 'yf-1ezv2n5')]\")\n",
    "    header = []\n",
    "    for div in divs:\n",
    "        text = div.text_content().strip() \n",
    "        header.append(text)\n",
    "    feature=['Date']\n",
    "    body = tree.xpath(\"//div[contains(@class, 'column') and contains(@class, 'sticky') and contains(@class, 'yf-1xjz32c')]\")\n",
    "    for isi in body:\n",
    "        text = isi.text_content().strip() \n",
    "        feature.append(text)\n",
    "    isi_data =[]\n",
    "    data = tree.xpath(\"//div[contains(@class, 'column') and not(contains(@class, 'sticky')) and contains(@class, 'yf-1xjz32c')]\")\n",
    "    for isi in data:\n",
    "        text = isi.text_content().strip() \n",
    "        isi_data.append(text)\n",
    "    print(isi_data)\n",
    "    list_kelompok=[[header[i] for i in range(1,len(header))]]\n",
    "    jumlah_per_kelompok = len(header)-1\n",
    "    for i in range(0, len(isi_data), jumlah_per_kelompok):\n",
    "        kelompok = isi_data[i:i + jumlah_per_kelompok]\n",
    "        list_kelompok.append(kelompok)\n",
    "    df = pd.DataFrame(columns=feature)\n",
    "    n = np.array(list_kelompok).T.tolist()\n",
    "    df = pd.DataFrame(n,columns=feature)\n",
    "    return df\n",
    "\n",
    "def scrape_lapkeu(stock_code):\n",
    "    if not os.path.exists('Laporan_keuangan'):\n",
    "        os.makedirs('Laporan_keuangan')\n",
    "    df = scrape_data_yahoo(stock_code,'financials')\n",
    "    df2 = scrape_data_yahoo(stock_code,'balance-sheet')\n",
    "    df3 = scrape_data_yahoo(stock_code,'cash-flow')\n",
    "    df_gabungan  = pd.merge(df, df2, on='Date', how='outer')\n",
    "    df_gabungan  = pd.merge(df_gabungan, df3, on='Date', how='outer')\n",
    "    df_gabungan\n",
    "    df_gabungan.to_csv('Laporan_keuangan/'+stock_code+'_laporan_keuangan.csv', index=False)\n",
    "\n",
    "# scrape_lapkeu('AVGO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81513328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lapkeu(reload_sp500 = False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    for i,s in enumerate(tickers[498:499]):\n",
    "        stock = s['ticker']\n",
    "        if '.' in stock:\n",
    "            stock = stock.replace('.','-')\n",
    "        print(i, stock)\n",
    "        scrape_lapkeu(stock)\n",
    "        time.sleep(2)\n",
    "\n",
    "# def lengkapi_data_lapkeu():\n",
    "#     dir = './Laporan_keuangan'\n",
    "#     for i in os.listdir(dir)[:]:\n",
    "#         file = os.path.join(dir, i)\n",
    "#         # print(file)\n",
    "#         if not os.path.isfile(file):\n",
    "#             # print(\"masuk 1\")\n",
    "#             continue\n",
    "#         if  os.path.getsize(file) > 1000:\n",
    "#             # print(\"masuk 2\")\n",
    "#             continue\n",
    "#         kode = i.split('_')[0]\n",
    "#         kode = kode.replace('.','-')\n",
    "#         print(kode)\n",
    "#         scrape_lapkeu(kode)\n",
    "#         c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a6920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcec0ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XYL\n",
      "<Response [200]>\n",
      "['8,396,000.00', '7,364,000.00', '5,522,000.00', '5,195,000.00', '4,876,000.00', '--', '5,305,000.00', '4,647,000.00', '3,438,000.00', '3,220,000.00', '3,046,000.00', '--', '3,091,000.00', '2,717,000.00', '2,084,000.00', '1,975,000.00', '1,830,000.00', '--', '2,154,000.00', '1,989,000.00', '1,573,000.00', '1,383,000.00', '1,330,000.00', '--', '937,000.00', '728,000.00', '511,000.00', '592,000.00', '500,000.00', '--', '-25,000.00', '-21,000.00', '-34,000.00', '-69,000.00', '-70,000.00', '--', '-74,000.00', '-72,000.00', '-37,000.00', '-12,000.00', '-145,000.00', '--', '838,000.00', '635,000.00', '440,000.00', '511,000.00', '285,000.00', '--', '73,000.00', '26,000.00', '85,000.00', '84,000.00', '31,000.00', '--', '765,000.00', '609,000.00', '355,000.00', '427,000.00', '254,000.00', '--', '765,000.00', '609,000.00', '355,000.00', '427,000.00', '254,000.00', '--', '3.25', '2.81', '1.97', '2.37', '1.41', '--', '3.24', '2.79', '1.96', '2.35', '1.40', '--', '241,600.00', '217,000.00', '180,200.00', '180,200.00', '180,100.00', '--', '242,850.00', '218,200.00', '181,000.00', '181,500.00', '181,100.00', '--', '864,000.00', '652,000.00', '622,000.00', '585,000.00', '367,000.00', '--', '7,459,000.00', '6,636,000.00', '5,011,000.00', '4,603,000.00', '4,376,000.00', '--', '765,000.00', '609,000.00', '355,000.00', '427,000.00', '254,000.00', '--', '836,205.25', '682,843.00', '377,624.00', '431,185.00', '372,503.00', '--', '--', '28,000.00', '16,000.00', '7,000.00', '7,000.00', '--', '53,000.00', '49,000.00', '50,000.00', '76,000.00', '77,000.00', '--', '-25,000.00', '-21,000.00', '-34,000.00', '-69,000.00', '-70,000.00', '--', '891,000.00', '684,000.00', '490,000.00', '587,000.00', '362,000.00', '--', '1,454,000.00', '1,120,000.00', '726,000.00', '832,000.00', '613,000.00', '--', '5,305,000.00', '4,647,000.00', '3,438,000.00', '3,220,000.00', '3,046,000.00', '--', '563,000.00', '436,000.00', '236,000.00', '245,000.00', '251,000.00', '--', '765,000.00', '609,000.00', '355,000.00', '427,000.00', '254,000.00', '--', '-78,000.00', '-77,000.00', '-28,000.00', '-5,000.00', '-133,000.00', '--', '-78,000.00', '-77,000.00', '-28,000.00', '-5,000.00', '-133,000.00', '--', '1,532,000.00', '1,197,000.00', '754,000.00', '837,000.00', '746,000.00', '--', '0.00', '0.00', '0.00', '0.00', '0.00', '--', '-6,794.75', '-3,157.00', '-5,376.00', '-815.00', '-14,497.00', '--']\n",
      "<Response [200]>\n",
      "['16,112,000.00', '7,952,000.00', '8,276,000.00', '8,750,000.00', '--', '5,936,000.00', '4,449,000.00', '5,050,000.00', '5,774,000.00', '--', '10,176,000.00', '3,503,000.00', '3,226,000.00', '2,976,000.00', '--', '12,434,000.00', '5,374,000.00', '5,658,000.00', '5,452,000.00', '--', '10,166,000.00', '3,494,000.00', '3,218,000.00', '2,968,000.00', '--', '106,000.00', '69,000.00', '69,000.00', '63,000.00', '--', '50,000.00', '-155,000.00', '-590,000.00', '-979,000.00', '--', '1,679,000.00', '1,422,000.00', '1,769,000.00', '1,567,000.00', '--', '12,450,000.00', '5,374,000.00', '5,658,000.00', '6,052,000.00', '--', '50,000.00', '-155,000.00', '-590,000.00', '-979,000.00', '--', '2,390,000.00', '1,949,000.00', '2,509,000.00', '3,147,000.00', '--', '1,265,000.00', '936,000.00', '1,091,000.00', '1,209,000.00', '--', '257,600.00', '196,000.00', '195,600.00', '194,900.00', '--', '241,600.00', '180,200.00', '180,400.00', '180,400.00', '--', '16,000.00', '15,800.00', '15,200.00', '14,500.00', '--']\n",
      "<Response [200]>\n",
      "['1,205,000.00', '837,000.00', '596,000.00', '538,000.00', '824,000.00', '--', '-267,000.00', '-628,000.00', '-191,000.00', '-183,000.00', '-169,000.00', '--', '-811,000.00', '-157,000.00', '-790,000.00', '-855,000.00', '473,000.00', '--', '835,000.00', '1,019,000.00', '944,000.00', '1,349,000.00', '1,875,000.00', '--', '186,000.00', '211,000.00', '91,000.00', '83,000.00', '41,000.00', '--', '75,000.00', '69,000.00', '76,000.00', '99,000.00', '77,000.00', '--', '-315,000.00', '-271,000.00', '-208,000.00', '-208,000.00', '-183,000.00', '--', '-71,000.00', '278,000.00', '--', '--', '1,344,000.00', '--', '-436,000.00', '-160,000.00', '-527,000.00', '-600,000.00', '-640,000.00', '--', '-34,000.00', '-25,000.00', '-52,000.00', '-68,000.00', '-61,000.00', '--', '890,000.00', '566,000.00', '388,000.00', '330,000.00', '641,000.00', '--']\n"
     ]
    }
   ],
   "source": [
    "get_lapkeu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6b87bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengkapi_data_lapkeu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d8a86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL_laporan_keuangan.csv',\n",
       " 'AAPL_laporan_keuangan.csv',\n",
       " 'ABBV_laporan_keuangan.csv',\n",
       " 'ABNB_laporan_keuangan.csv',\n",
       " 'ABT_laporan_keuangan.csv',\n",
       " 'ACGL_laporan_keuangan.csv',\n",
       " 'ACN_laporan_keuangan.csv',\n",
       " 'ADBE_laporan_keuangan.csv',\n",
       " 'ADI_laporan_keuangan.csv',\n",
       " 'ADM_laporan_keuangan.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./Laporan_keuangan')[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
